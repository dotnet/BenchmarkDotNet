<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
      <title>How it works | BenchmarkDotNet </title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="title" content="How it works | BenchmarkDotNet ">
      
      
      <link rel="icon" href="../../logo/icon-32.png">
      <link rel="stylesheet" href="../../public/docfx.min.css">
      <link rel="stylesheet" href="../../public/main.css">
      <meta name="docfx:navrel" content="../../toc.html">
      <meta name="docfx:tocrel" content="../toc.html">
      
      <meta name="docfx:rel" content="../../">
      
      
      <meta name="docfx:docurl" content="https://github.com/dotnet/BenchmarkDotNet/blob/master/docs/articles/guides/how-it-works.md/#L1">
      <meta name="loc:inThisArticle" content="In this article">
      <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
      <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
      <meta name="loc:tocFilter" content="Filter by title">
      <meta name="loc:nextArticle" content="Next">
      <meta name="loc:prevArticle" content="Previous">
      <meta name="loc:themeLight" content="Light">
      <meta name="loc:themeDark" content="Dark">
      <meta name="loc:themeAuto" content="Auto">
      <meta name="loc:changeTheme" content="Change theme">
      <meta name="loc:copy" content="Copy">
      <meta name="loc:downloadPdf" content="Download PDF">

      <script type="module" src="./../../public/docfx.min.js"></script>

      <script>
        const theme = localStorage.getItem('theme') || 'auto'
        document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
      </script>

  </head>

  <body class="tex2jax_ignore" data-layout="" data-yaml-mime="">
    <header class="bg-body border-bottom">
      <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
        <div class="container-xxl flex-nowrap">
          <a class="navbar-brand" href="../../index.html">
            <img id="logo" class="svg" src="../../logo/icon.svg" alt="">
            
          </a>
          <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
          <div class="collapse navbar-collapse" id="navpanel">
            <div id="navbar">
              <form class="search" role="search" id="search">
                <i class="bi bi-search"></i>
                <input class="form-control" id="search-query" type="search" disabled placeholder="Search" autocomplete="off" aria-label="Search">
              </form>
            </div>
          </div>
        </div>
      </nav>
    </header>

    <main class="container-xxl">
      <div class="toc-offcanvas">
        <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
          <div class="offcanvas-header">
            <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
            <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
          </div>
          <div class="offcanvas-body">
            <nav class="toc" id="toc"></nav>
          </div>
        </div>
      </div>

      <div class="content">
        <div class="actionbar">
          <button class="btn btn-lg border-0 d-md-none" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
            <i class="bi bi-list"></i>
          </button>

          <nav id="breadcrumb"></nav>
        </div>

        <article data-uid="">
<h1 id="how-it-works">How it works</h1>

<p>BenchmarkDotNet follows the following steps to run your benchmarks:</p>
<ol>
<li><code>BenchmarkRunner</code> generates an isolated project per each runtime settings and builds it in Release mode.</li>
<li>Next, we take each method/job/params combination and try to measure its performance by launching benchmark process several times (<code>LaunchCount</code>).</li>
<li>An invocation of the workload method is an <em>operation</em>. A bunch of operation is an <em>iteration</em>. If you have an <code>IterationSetup</code> method, it will be invoked before each iteration,
but not between operations. We have the following type of iterations:
<ul>
<li><code>Pilot</code>: The best operation count will be chosen.</li>
<li><code>OverheadWarmup</code>, <code>OverheadWorkload</code>: BenchmarkDotNet overhead will be evaluated.</li>
<li><code>ActualWarmup</code>: Warmup of the workload method.</li>
<li><code>ActualWorkload</code>: Actual measurements.</li>
<li><code>Result</code> = <code>ActualWorkload</code> - <code>&lt;MedianOverhead&gt;</code></li>
</ul>
</li>
<li>After all of the measurements, BenchmarkDotNet creates:
<ul>
<li>An instance of the <code>Summary</code> class that contains all information about benchmark runs.</li>
<li>A set of files that contains summary in human-readable and machine-readable formats.</li>
<li>A set of plots.</li>
</ul>
</li>
</ol>
<h2 id="pseudocode">Pseudocode</h2>
<p>If you don't understand our &quot;count terminology&quot;, then you might find following pseudocode useful:</p>
<pre><code class="lang-cs">IEnumerable&lt;Results&gt; Run(Benchmark benchmark)
{
    var toolchain = benchmark.GetToolchain();

    var autoGeneratedProject = toolchain.Generate(benchmark);
    var exe = toolchain.Build(autoGeneratedProject);

    foreach (var runIndex in LaunchCount) // LaunchCount = 1 by default
        yield return ParseResults(Process.Start(exe).Output); // calls ActualRun in a separate process
}

Result ActualRun(Method method, Job job)
{
    GlobalSetup();

    int unrollFactor = job.Run.UnrollFactor; // 16 by default

    long perfectInvocationCount = Pilot(method, unrollFactor);

    WarmupStage(EMPTY_METHOD, perfectInvocationCount, unrollFactor); // EMPTY_METHOD has same return type and arguments as benchmark
    var overhead = ActualStage(EMPTY_METHOD, perfectInvocationCount, unrollFactor);

    WarmupStage(method, perfectInvocationCount, unrollFactor);
    var result = ActualStage(method, perfectInvocationCount);

    if (MemoryDiagnoser.IsEnabled)
        var gcStats = MeasureGcStats(method, perfectInvocationCount, unrollFactor);

    GlobalCleanup(); 

    return (result - Median(overhead), gcStats);
}

long Pilot(Method method, int unrollFactor)
{
    // invokeCount is the equivalent of InnerIterationCount from xunit-performance
    long invokeCount = minInvokeCount;

    while (true)
    {
        var measurement = RunIteration(method, invokeCount, unrollFactor);

        if (heuristic.IsPilotRequirementMet(measurement))
            break;

        invokeCount *= 2;
    }

    return invokeCount;
}

void Warmup(Method method, long invokeCount, int unrollFactor)
{
    while (true)
    {
        var measurement = RunIteration(method, invokeCount, unrollFactor);

        if (heuristic.IsWarmupRequirementMet(measurement))
            break;
    }
}

IEnuberable&lt;Measurement&gt; Workload(Method method, long invokeCount, int unrollFactor)
{
    while (true)
    {
        var measurement = RunIteration(method, invokeCount, unrollFactor);

        if (measurement.IsNotOutlier)
            yield return measurement;

        if (heuristic.IsWorkloadRequirementMet(measurement))
            yield break;
    }
}

// every iteration invokes the method (invokeCount / unrollFactor) times
Measurement RunIteration(Method method, long invokeCount, long unrollFactor)
{
    IterationSetup();
    MemoryCleanup();

    var clock = Clock.Start();

    for (long i = 0; i &lt; invokeCount / unrollFactor; i++)
    {
        // we perform manual loop unrolling!!
        method(); // 1st call
        method(); // 2nd call

        method(); // (unrollFactor - 1)'th call
        method(); // unrollFactor'th call
    }

    var clockSpan = clock.GetElapsed();

    IterationCleanup();
    MemoryCleanup();

    return Measurement(clockSpan);
}

GcStats MeasureGcStats(Method method, long invokeCount, long unrollFacto)
{
    // we enable monitoring after workload actual run, for this single iteration which is executed at the end
    // so even if we enable AppDomain monitoring in separate process
    // it does not matter, because we have already obtained the results!
    EnableMonitoring(); 

    IterationSetup();

    var initialGcStats = GcStats.ReadInitial();

    // we do NOT start any clock here, because the enabled monitoring might have some overhead
    // so we just get the gc stats and ignore the timing
    // it's last thing the process does before it dies, so also enabled monitoring is not an issue for next benchmarks
    // because each of them is going to be executed in a new process

    for (long i = 0; i &lt; invokeCount / unrollFactor; i++)
    {
        // we perform manual loop unrolling!!
        method(); // 1st call
        method(); // 2nd call

        method(); // (unrollFactor - 1)'th call
        method(); // unrollFactor'th call
    }

    var finalGcStats = GcStats.ReadFinal();

    IterationCleanup();

    return finalGcStats - initialGcStats; // the result is the difference between the stats collected after and before running the extra iteration
}
</code></pre>

</article>


        <div class="next-article d-print-none border-top" id="nextArticle"></div>

      </div>

      <div class="affix">
        <nav id="affix"></nav>
      </div>
    </main>

    <div class="container-xxl search-results" id="search-results"></div>

    <footer class="border-top text-secondary">
      <div class="container-xxl">
        <div class="flex-fill">
          Copyright &copy; 2013â€“2024 .NET Foundation and contributors
        </div>
      </div>
    </footer>
  </body>
</html>
