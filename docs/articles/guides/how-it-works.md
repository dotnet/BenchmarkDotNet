# How it works

BenchmarkDotNet follows the following steps to run your benchmarks:

1. `BenchmarkRunner` generates an isolated project per each runtime settings and builds it in Release mode.
2. Next, we take each method/job/params combination and try to measure its performance by launching benchmark process several times (`LaunchCount`).
3. An invocation of the target method is an *operation*. A bunch of operation is an *iteration*. If you have an `IterationSetup` method, it will be invoked before each iteration, 
but not between operations. We have the following type of iterations:
    * `Pilot`: The best operation count will be chosen.
    * `IdleWarmup`, `IdleTarget`: BenchmarkDotNet overhead will be evaluated.
    * `MainWarmup`: Warmup of the main method.
    * `MainTarget`: Main measurements.
    * `Result` = `MainTarget` - `<AverageOverhead>`
4. After all of the measurements, BenchmarkDotNet creates:
    * An instance of the `Summary` class that contains all information about benchmark runs.
    * A set of files that contains summary in human-readable and machine-readable formats.
    * A set of plots.

## Pseudocode

If you don't understand our "count terminology", then you might find following pseudocode useful:

```cs
IEnumberable<Results> Run(Benchmark benchmark)
{
    var toolchain = benchmark.GetToolchain();

    var autoGeneratedProject = toolchain.Generate(benchmark);
    var exe = toolchain.Build(autoGeneratedProject);

    foreach (var runIndex in LaunchCount) // LaunchCount = 1 by default
        yield return ParseResults(Process.Start(exe).Output); // calls ActualRun in a separate process
}

Result ActualRun(Method method)
{
    GlobalSetup();

    long perfectInvocationCount = Pilot(method);

    Warmup(EMPTY_METHOD, perfectInvocationCount); // EMPTY_METHOD has same return type and arguments as benchmark
    var overhead = Target(EMPTY_METHOD, perfectInvocationCount);

    Warmup(method, perfectInvocationCount);
    var result = Target(method, perfectInvocationCount);

    GlobalCleanup(); 

    return result - Avg(overhead);
}

long Pilot(Method method)
{
    // invokeCount is the equivalent of InnerIterationCount from xunit-performance
    long invokeCount = minInvokeCount;

    while (true)
    {
        var measurement = RunIteration(method, invokeCount, unrollFactor);

        if (heuristic.IsPilotRequirementMet(measurement))
            break;

        invokeCount *= 2;
    }

    return invokeCount;
}

void Warmup(Method method, long invokeCount)
{
    while (true)
    {
        var measurement = RunIteration(method, invokeCount, unrollFactor);

        if (heuristic.IsWamupRequirementMet(measurement))
            break;
    }
}

IEnumberable<Measurement> Target(Method method, long invokeCount)
{
    while (true)
    {
        var measurement = RunIteration(method, invokeCount, unrollFactor);

        if (measurement.IsNotOutlier)
            yield return measurement;

        if (heuristic.IsTargetRequirementMet(measurement))
            yield break;
    }
}

// every iteration invokes the method (invokeCount / unrollFactor) times
Measurement RunIteration(Method method, long invokeCount, long unrollFactor)
{
    IterationSetup();
    MemoryCleanup();

    var clock = Clock.Start();

    for (long i = 0; i < invokeCount / unrollFactor; i++)
    {
        // we perform manuall loop unrolling!!
        method(); // 1st call
        method(); // 2nd call

        method(); // (unrollFactor - 1)'th call
        method(); // unrollFactor'th call
    }

    var clockSpan = clock.GetElapsed();

    IterationCleanup();
    MemoryCleanup();

    return Measurement(clockSpan);
}
```
